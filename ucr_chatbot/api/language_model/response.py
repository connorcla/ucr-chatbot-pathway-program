from typing import Generator


def get_response_from_prompt(prompt: str, max_tokens: int = 3000) -> str:
    """Gets a response from a language model.

    :param prompt: The prompt to feed into the language model.
    :param max_tokens: The maximal number of tokens generated by the language model.
    :return: The completion from the language model.
    """
    return f"Echoing: {prompt}, {max_tokens}"


def stream_response_from_prompt(prompt: str, max_tokens: int = 3000) -> Generator[str]:
    """Streams a response from a language.

    :param prompt: The prompt to feed into the language model.
    :param max_tokens: The maximal number of tokens generated by the language model.
    :yield: The next substring of the language model's completion
    """
    yield from f"Streamed Echoing: {prompt}, {max_tokens}"
